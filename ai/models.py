import cv2
import mediapipe as mp
import numpy as np
import xgboost as xgb
import os
import json # å¿…é ˆå°å…¥æ­¤åº«ä»¥è™•ç†æ¨™ç±¤æª”æ¡ˆ
import sys

def resource_path(relative_path):
    """ å–å¾—è³‡æºçµ•å°è·¯å¾‘ï¼Œç›¸å®¹æ–¼é–‹ç™¼èˆ‡ PyInstaller æ‰“åŒ…ç’°å¢ƒ """
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)

class PoseEngine:
    """
    è™•ç† MediaPipe Pose åµæ¸¬èˆ‡ XGBoost å§¿å‹¢è¾¨è­˜
    """
    def __init__(self, model_path="yoga_pose_model_RightFoot.json", labels_path="rightfoot.json"):
        print("[AI Engine] æ­£åœ¨åˆå§‹åŒ–...", flush=True)
        
        # è½‰æ›ç‚ºè³‡æºè·¯å¾‘
        self.actual_model_path = resource_path(model_path)
        self.actual_labels_path = resource_path(labels_path)
        
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        self.user_style = self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=3, circle_radius=3)

        # 1. åˆå§‹åŒ– XGBoost
        self.classifier = xgb.Booster()
        if os.path.exists(self.actual_model_path):
            self.classifier.load_model(self.actual_model_path)
            self.model_loaded = True
            print(f"[AI Engine] ğŸš€ æˆåŠŸè¼‰å…¥æ¨¡å‹: {self.actual_model_path}", flush=True)
        else:
            self.model_loaded = False
            print(f"[AI Engine] âš ï¸ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {self.actual_model_path}ï¼Œå°‡åªé¡¯ç¤ºéª¨æ¶", flush=True)

        # 2. åˆå§‹åŒ–æ¨™ç±¤
        self.labels = {}
        self._load_labels()

    def _load_labels(self):
        """ è¼‰å…¥æ¨™ç±¤ JSON æª”æ¡ˆ """
        if os.path.exists(self.actual_labels_path):
            try:
                with open(self.actual_labels_path, 'r', encoding='utf-8') as f:
                    raw_labels = json.load(f)
                    # ç¢ºä¿ key è½‰æ›ç‚ºæ•´æ•¸ï¼Œå› ç‚º XGB é æ¸¬çµæœæ˜¯æ•¸å€¼ç´¢å¼•
                    self.labels = {int(k): v for k, v in raw_labels.items()}
                print(f"[AI Engine] âœ… æˆåŠŸè¼‰å…¥æ¨™ç±¤: {self.labels}")
            except Exception as e:
                print(f"[AI Engine] âŒ æ¨™ç±¤æª”æ¡ˆè§£æå¤±æ•—: {e}")
                self.labels = {0: "å§¿å‹¢åç§» (é è¨­)", 1: "æ­£ç¢ºå‹•ä½œ (é è¨­)"}
        else:
            print(f"[AI Engine] âš ï¸ æ‰¾ä¸åˆ°æ¨™ç±¤æª”æ¡ˆæ–¼: {self.actual_labels_path}")
            self.labels = {0: "å§¿å‹¢åç§» (é è¨­)", 1: "æ­£ç¢ºå‹•ä½œ (é è¨­)"}

    def process(self, frame):
        """
        è™•ç†å½±æ ¼
        å›å‚³: (æ¨™è¨˜å½±åƒ, éª¨éª¼æ•¸æ“š, è¾¨è­˜å›é¥‹æ–‡å­—)
        """
        if frame is None: return None, None, "No Signal"
        
        annotated_frame = frame.copy()
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(frame_rgb)
        
        feedback = "è«‹é€²å…¥ç•«é¢"
        skeleton_data = None

        if results.pose_landmarks:
            skeleton_data = results.pose_landmarks
            self.mp_drawing.draw_landmarks(
                annotated_frame, 
                skeleton_data, 
                self.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.user_style
            )
            
            # åŸ·è¡Œè¾¨è­˜
            if self.model_loaded:
                feedback = self._predict_pose(skeleton_data)
            else:
                feedback = "éª¨æ¶åµæ¸¬ä¸­..."
            
        return annotated_frame, skeleton_data, feedback

    def _predict_pose(self, landmarks):
        """ æ ¹æ“š 20 å€‹é—œéµé» (40ç¶­ç‰¹å¾µ) é€²è¡Œé æ¸¬ """
        try:
            features = []
            # æå–è‚©è†€ (11) åˆ°è…³è¸ (30) çš„é»
            for i in range(11, 31):
                lm = landmarks.landmark[i]
                features.extend([lm.x, lm.y])
            
            input_data = np.array([features], dtype=np.float32)
            data = xgb.DMatrix(input_data)
            preds = self.classifier.predict(data)
            
            # å–å¾—ä¿¡å¿ƒåº¦æœ€é«˜çš„é¡åˆ¥
            class_idx = np.argmax(preds[0])
            confidence = preds[0][class_idx]
            
            if confidence > 0.7:
                # é€™è£¡æœƒå¾è®€å–çš„ self.labels ä¸­æŠ“å–å°æ‡‰æ–‡å­—
                return self.labels.get(class_idx, f"æœªçŸ¥å‹•ä½œ (ID:{class_idx})")
            
            return "å‹•ä½œåŒ¹é…ä¸­..."
        except Exception as e:
            # å°å‡ºå…·é«”éŒ¯èª¤ä»¥ä¾¿èª¿è©¦
            # print(f"é æ¸¬éŒ¯èª¤: {e}")
            return "åˆ†æä¸­..."

class VTuberRenderer:
    """ æ¸²æŸ“ç´”é»‘èƒŒæ™¯çš„éª¨æ¶åœ– (ç”¨æ–¼ GUI é¡¯ç¤º) """
    def __init__(self):
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_pose = mp.solutions.pose
        self.style = self.mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=4)

    def render(self, skeleton_data):
        canvas = np.zeros((480, 640, 3), dtype="uint8")
        if skeleton_data:
            self.mp_drawing.draw_landmarks(
                canvas, 
                skeleton_data, 
                self.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.style
            )
        return canvas