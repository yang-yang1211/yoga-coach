import cv2
import mediapipe as mp
import numpy as np
import xgboost as xgb
import os
import time

class PoseEngine:
    """
    è™•ç† MediaPipe Pose åµæ¸¬èˆ‡ XGBoost å§¿å‹¢è¾¨è­˜
    """
    def __init__(self, model_path="yoga_pose_model_RightFoot.json",labels_path="rightfoot.json"):
        print("[AI Engine] æ­£åœ¨åˆå§‹åŒ–...", flush=True)
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        self.user_style = self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=3, circle_radius=3)

        # åˆå§‹åŒ– XGBoost
        self.classifier = xgb.Booster()
        if os.path.exists(model_path):
            self.classifier.load_model(model_path)
            self.model_loaded = True
            print(f"[AI Engine] ğŸš€ æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_path}", flush=True)
        else:
            self.model_loaded = False
            print(f"[AI Engine] âš ï¸ æ‰¾ä¸åˆ°æ¨¡å‹ï¼Œå°‡åªé¡¯ç¤ºéª¨æ¶", flush=True)

        self.labels = {}
        if os.path.exists(labels_path):
            try:
                with open(labels_path, 'r', encoding='utf-8') as f:
                    # å‡è¨­ JSON æ ¼å¼ç‚º {"0": "å‹•ä½œA", "1": "å‹•ä½œB"}
                    raw_labels = json.load(f)
                    # ç¢ºä¿ key ç‚ºæ•´æ•¸
                    self.labels = {int(k): v for k, v in raw_labels.items()}
                print(f"[AI Models] æˆåŠŸè¼‰å…¥æ¨™ç±¤æª”æ¡ˆ: {labels_path}")
            except Exception as e:
                print(f"[AI Models] æ¨™ç±¤æª”æ¡ˆæ ¼å¼éŒ¯èª¤: {e}")
                self.labels = {0: "å§¿å‹¢åç§»", 1: "æ­£ç¢ºå³å¹³è¡¡"} # å‚™ç”¨æ¨™ç±¤
        else:
            print(f"[AI Models] âš ï¸ æ‰¾ä¸åˆ°æ¨™ç±¤æª”æ¡ˆï¼Œä½¿ç”¨é è¨­æ¨™ç±¤")
            self.labels = {0: "å§¿å‹¢åç§»", 1: "æ­£ç¢ºå³å¹³è¡¡"}

    def process(self, frame):
        """
        è™•ç†å½±æ ¼
        å›å‚³: (æ¨™è¨˜å½±åƒ, éª¨éª¼æ•¸æ“š, è¾¨è­˜å›é¥‹æ–‡å­—)
        """
        if frame is None: return None, None, "No Signal"
        
        annotated_frame = frame.copy()
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(frame_rgb)
        
        feedback = "è«‹é€²å…¥ç•«é¢"
        skeleton_data = None

        if results.pose_landmarks:
            skeleton_data = results.pose_landmarks
            self.mp_drawing.draw_landmarks(
                annotated_frame, 
                skeleton_data, 
                self.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.user_style
            )
            
            # åŸ·è¡Œè¾¨è­˜
            if self.model_loaded:
                feedback = self._predict_pose(skeleton_data)
            else:
                feedback = "åµæ¸¬ä¸­..."
            
        return annotated_frame, skeleton_data, feedback

    def _predict_pose(self, landmarks):
        try:
            features = []
            for i in range(11, 31): # æå–è‚©è†€åˆ°è…³è¸çš„ 20 å€‹é» (40ç¶­)
                lm = landmarks.landmark[i]
                features.extend([lm.x, lm.y])
            
            input_data = np.array([features], dtype=np.float32)
            data = xgb.DMatrix(input_data)
            preds = self.classifier.predict(data)
            
            class_idx = np.argmax(preds[0])
            confidence = preds[0][class_idx]
            
            if confidence > 0.7:
                return self.labels.get(class_idx, "æœªçŸ¥å‹•ä½œ")
            return "æ­£åœ¨æ•æ‰å‹•ä½œ..."
        except:
            return "åˆ†æä¸­..."

class VTuberRenderer:
    def __init__(self):
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_pose = mp.solutions.pose
        self.style = self.mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=4)

    def render(self, skeleton_data):
        canvas = np.zeros((480, 640, 3), dtype="uint8")
        if skeleton_data:
            self.mp_drawing.draw_landmarks(
                canvas, 
                skeleton_data, 
                self.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.style
            )
        return canvas