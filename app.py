import sys
import time
import os
import cv2
import json
import mediapipe as mp
import numpy as np
from PyQt6.QtWidgets import QApplication, QMainWindow
from PyQt6.QtCore import QThread, pyqtSignal, Qt, QTimer
from PyQt6.QtGui import QImage

# åŒ¯å…¥å°ˆæ¡ˆè‡ªå®šç¾©æ¨¡çµ„
try:
    from ui.main import MainUI
    from ai.models import PoseEngine, VTuberRenderer
    from core.state import SystemState
    from core.gesture_engine import GestureEngine
    # å¾æ›´æ–°å¾Œçš„å¼•æ“åŒ¯å…¥ Gemini èˆ‡ Ollama
    from ai.llm_engine import GeminiCoach, OllamaCoach 
except ImportError as e:
    print(f"[Import Error] ç¼ºå°‘æ¨¡çµ„: {e}")

def resource_path(relative_path):
    """ å–å¾—è³‡æºçµ•å°è·¯å¾‘ï¼Œå…¼å®¹é–‹ç™¼ç’°å¢ƒèˆ‡ PyInstaller æ‰“åŒ…ç’°å¢ƒ """
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)

# --- 1. LLM éåŒæ­¥è™•ç†åŸ·è¡Œç·’ (æ”¯æ´åº§æ¨™åˆ†æ) ---
class LLMWorker(QThread):
    finished = pyqtSignal(str)

    def __init__(self, coach, status, landmarks):
        super().__init__()
        self.coach = coach
        self.status = status
        self.landmarks = landmarks

    def run(self):
        """ åŸ·è¡Œ AI è«‹æ±‚ """
        if not self.coach:
            self.finished.emit("æ•™ç·´ç›®å‰ä¸åœ¨ç·šä¸Šã€‚")
            return

        # å°‡åº§æ¨™å­—å…¸è½‰ç‚ºæ–‡å­—æè¿°ï¼Œè®“ AI æ›´å¥½åˆ¤æ–·
        # ä¾‹å¦‚ï¼šL_Knee:(0.50, 0.80), R_Knee:(0.52, 0.82)
        lm_str = ", ".join([f"{k}:({v[0]:.2f}, {v[1]:.2f})" for k, v in self.landmarks.items()])
        
        # æ§‹é€ ç²¾ç¢ºçš„ Prompt
        query = (
            f"ä½¿ç”¨è€…ç›®å‰å§¿å‹¢æ¨™ç±¤ç‚º: {self.status}ã€‚ "
            f"é—œéµé»åº§æ¨™(æ­¸ä¸€åŒ–): {lm_str}ã€‚ "
            "è«‹åˆ¤æ–·ä½¿ç”¨è€…å‹•ä½œå“ªè£¡ä¸æ¨™æº–ï¼Œä¸¦çµ¦å‡ºä¸€å¥ 20 å­—å…§çš„å…·é«”ä¿®æ­£å»ºè­°ã€‚"
        )

        res = self.coach.ask(query)
        self.finished.emit(res)

# --- 2. å½±åƒè™•ç†æ ¸å¿ƒåŸ·è¡Œç·’ (è² è²¬æå–åº§æ¨™èˆ‡å½±åƒ) ---
class VideoThread(QThread):
    raw_ready = pyqtSignal(QImage)
    vt_ready = pyqtSignal(QImage)
    # æ“´å±•è¨Šè™Ÿ: (is_active, fps, feedback, hand_x, hand_y, pose_landmarks)
    status_update = pyqtSignal(bool, float, str, float, float, dict)
    gesture_cmd = pyqtSignal(str)

    def __init__(self, state):
        super().__init__()
        self.state = state
        self.pose = PoseEngine(
            model_path=resource_path("yoga_pose_model_RightFoot.json"),
            labels_path=resource_path("rightfoot.json")
        )
        self.vt = VTuberRenderer()
        self.gesture_engine = GestureEngine()
        
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )

    def run(self):
        print("[VideoThread] æ­£åœ¨é–‹å•Ÿæ”å½±æ©Ÿ...", flush=True)
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("[VideoThread] âŒ éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ", flush=True)
            return

        last_time = time.time()
        while not self.state.stop_signal:
            ret, frame = cap.read()
            if not ret: continue
            
            frame = cv2.flip(frame, 1)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            anno_frame = frame.copy()
            skeleton = None
            feedback = ""
            is_active = False
            hand_x, hand_y = -1.0, -1.0
            pose_landmarks = {}

            if self.state.mode == "EXERCISE":
                anno_frame, skeleton, feedback = self.pose.process(frame)
                if skeleton:
                    # 1. æå–å³é£ŸæŒ‡ä½ç½®ä¾›æ‡¸æµ®æ§åˆ¶
                    r_idx = skeleton.landmark[20]
                    if r_idx.visibility > 0.5:
                        hand_x, hand_y = r_idx.x, r_idx.y
                    
                    # 2. æå–é—œéµé—œç¯€åº§æ¨™ä¾› AI å»ºè­°ä½¿ç”¨
                    # 11,12:è‚© | 23,24:é«– | 25,26:è† | 27,28:è¸
                    targets = {"L_Shoulder": 11, "R_Shoulder": 12, "L_Knee": 25, "R_Knee": 26, "L_Ankle": 27, "R_Ankle": 28}
                    for name, idx in targets.items():
                        lm = skeleton.landmark[idx]
                        if lm.visibility > 0.5:
                            pose_landmarks[name] = [lm.x, lm.y]
            else:
                results = self.hands.process(rgb_frame)
                feedback = "æ‰‹éƒ¨æ“æ§æ¨¡å¼"
                if results.multi_hand_landmarks:
                    lm = results.multi_hand_landmarks[0]
                    is_fist = self.gesture_engine.is_fist(lm)
                    cmd = self.gesture_engine.get_swipe_command(lm, is_fist, self.state.current_page)
                    hand_x, hand_y = lm.landmark[8].x, lm.landmark[8].y
                    if cmd:
                        self.gesture_cmd.emit(cmd)

            def to_qimg(img):
                h, w, c = img.shape
                return QImage(img.data, w, h, c*w, QImage.Format.Format_BGR888).copy()

            self.raw_ready.emit(to_qimg(anno_frame))
            self.vt_ready.emit(to_qimg(self.vt.render(skeleton)))
            
            curr_time = time.time()
            fps = 1.0 / (curr_time - last_time) if (curr_time - last_time) > 0 else 0
            last_time = curr_time
            
            self.status_update.emit(is_active, fps, feedback, hand_x, hand_y, pose_landmarks)
            
        cap.release()
        self.hands.close()

# --- 3. ä¸»ç¨‹åºå…¥å£ ---
def main():
    print("[System] æ­£åœ¨å•Ÿå‹•ç¨‹åº...", flush=True)
    app = QApplication(sys.argv)
    
    state = SystemState()
    ui = MainUI(state)

    # ğŸ’¡ å„ªå…ˆåˆå§‹åŒ– GeminiCoach (é›²ç«¯ç‰ˆï¼Œå…å®‰è£ Ollama)
    coach = None
    try:
        # åœ¨é–‹ç™¼ç’°å¢ƒä¸­ï¼ŒapiKey ä¿æŒç‚ºç©ºï¼ŒåŸ·è¡Œç’°å¢ƒæœƒè‡ªå‹•å¡«å…¥
        coach = GeminiCoach(api_key="AIzaSyDiJH-K5PfEaXlcrqK7HSiTCGz66N3Z1vc") 
        print("[Main] âœ… Gemini AI æ•™ç·´å·²å°±ç·’", flush=True)
    except Exception as e:
        print(f"[Main] âš ï¸ Gemini åˆå§‹åŒ–å¤±æ•—: {e}ï¼Œå˜—è©¦å›é€€è‡³ Ollama", flush=True)
        try:
            coach = OllamaCoach()
        except:
            coach = None

    video = VideoThread(state)
    video.raw_ready.connect(ui.update_video)
    video.vt_ready.connect(ui.update_vtuber)
    video.gesture_cmd.connect(ui.handle_command)

    # --- 4. æ™ºæ…§æ•™ç·´è§¸ç™¼é‚è¼¯ ---
    last_coach_time = 0
    last_status = ""

    def handle_coach_trigger(is_active, fps, feedback, x, y, pose_data):
        nonlocal last_coach_time, last_status
        # æ›´æ–°ä»‹é¢ç‹€æ…‹ (åŸæœ¬ ui.update_status æ¥æ”¶ 5 å€‹åƒæ•¸)
        ui.update_status(is_active, fps, feedback, x, y)
        
        if state.mode != "EXERCISE" or coach is None: return
        
        current_time = time.time()
        # è§¸ç™¼æ¢ä»¶ï¼š15ç§’å†·å»ä¸”ç‹€æ…‹æ–‡å­—æœ‰è®Šä¸”æœ‰åº§æ¨™æ•¸æ“š
        if current_time - last_coach_time > 15 and pose_data:
            if feedback != last_status and ("æ­£ç¢º" in feedback or "åç§»" in feedback):
                execute_llm_request(feedback, pose_data)

    def execute_llm_request(status_text, landmarks):
        """ å•Ÿå‹• LLM Worker """
        nonlocal last_coach_time, last_status
        print(f"[Coach] æ­£åœ¨ç²å–å»ºè­°: {status_text}", flush=True)
        
        last_coach_time = time.time()
        last_status = status_text
        
        worker = LLMWorker(coach, status_text, landmarks)
        if hasattr(ui, 'show_coach'):
            worker.finished.connect(ui.show_coach)
        
        ui._current_llm_worker = worker 
        worker.start()

    # --- 5. æ‰‹å‹•æ¸¬è©¦é‚è¼¯ (T éµ) ---
    original_key_press = ui.keyPressEvent
    def manual_test_trigger(event):
        if event.key() == Qt.Key.Key_T:
            print("[Test] æ‰‹å‹•æ¸¬è©¦é–‹å§‹...", flush=True)
            # æ¸¬è©¦ç”¨å‡åº§æ¨™
            test_lms = {"R_Knee": [0.5, 0.8], "L_Knee": [0.5, 0.5]}
            execute_llm_request("æ­£ç¢ºå³å¹³è¡¡ (æ¸¬è©¦)", test_lms)
        elif original_key_press:
            original_key_press(event)

    ui.keyPressEvent = manual_test_trigger
    video.status_update.connect(handle_coach_trigger)

    video.start()
    ui.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()